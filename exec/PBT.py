def train(population,)
# for worker in worker_list:
#     while(worker's Q gradient is not below convergenceTolerance):
#       worker.setTheta(step(Î¸,h))
#       worker's eval = eval(theta(new))
#       if worker.ready():
#             [h_prime, theta_prime] = exploit(worker_list)
#             if worker.getTheta() != theta_prime:
#               worker = worker.update(h_prime, theta_prime) #???
#               worker.setP = worker.eval() #???

#
#
#

# DIRNAME = os.path.dirname(__file__)
# trajectoryDirectory = os.path.join(DIRNAME, '..', '..', 'data', 'evaluateObstacle',
#                                    'trajectories')
# if not os.path.exists(trajectoryDirectory):
#     os.makedirs(trajectoryDirectory)
